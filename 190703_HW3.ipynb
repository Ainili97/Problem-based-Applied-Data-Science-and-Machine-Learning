{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction\n",
    "\n",
    "作業檔案：\n",
    "- hw3.ipynb\n",
    "\n",
    "資料：\n",
    "https://www.sharecast.com/index/SP_500/prices/download\n",
    "\n",
    "- train.csv: S&P 500 訓練資料(2009-2017)\n",
    "- test.csv: S&P 500 測試資料(2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-2009</td>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-2009</td>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-2009</td>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
       "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
       "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
       "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "drop_col_names = ['Date'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "0      902.99       931.80      934.73     899.35  4048270080   \n",
      "1      929.17       927.45      936.63     919.53  5413910016   \n",
      "2      931.17       934.70      943.85     927.28  5392620032   \n",
      "3      927.45       906.65      927.45     902.37  4704940032   \n",
      "4      905.73       909.73      910.00     896.81  4991549952   \n",
      "\n",
      "   Tomorrow Movement  \n",
      "0                0.0  \n",
      "1                1.0  \n",
      "2                0.0  \n",
      "3                1.0  \n",
      "4                0.0  \n",
      "      Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "2259     2684.22      2683.34     2685.35    2678.13  1383888512   \n",
      "2260     2679.09      2680.50     2682.74    2677.96  1103808384   \n",
      "2261     2682.10      2682.62     2685.64    2678.91  1149108352   \n",
      "2262     2686.10      2687.54     2687.66    2682.69  1126089856   \n",
      "2263     2689.15      2673.61     2692.12    2673.61  1332374016   \n",
      "\n",
      "      Tomorrow Movement  \n",
      "2259                0.0  \n",
      "2260                1.0  \n",
      "2261                1.0  \n",
      "2262                0.0  \n",
      "2263                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with the previous days as the training target\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !--- You can add your own data preprocessing here ---!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 6)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(2263,)\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(251, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n",
      "(251,)\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "train_x_df = train_df.drop(columns=['Tomorrow Movement'])\n",
    "train_y_df = train_df['Tomorrow Movement']\n",
    "\n",
    "test_x_df = test_df.drop(columns=['Tomorrow Movement'])\n",
    "test_y_df = test_df['Tomorrow Movement']\n",
    "\n",
    "print(train_x_df.shape)\n",
    "print(train_x_df.head())\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())\n",
    "print('-----')\n",
    "print(test_x_df.shape)\n",
    "print(test_x_df.head())\n",
    "print(test_y_df.shape)\n",
    "print(test_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price    Volume\n",
      "0   -1.552572    -1.494607   -1.505683  -1.541181  0.813175\n",
      "1   -1.498571    -1.503581   -1.501760  -1.499581  1.823826\n",
      "2   -1.494446    -1.488625   -1.486853  -1.483605  1.808070\n",
      "3   -1.502119    -1.546489   -1.520714  -1.534956  1.299148\n",
      "4   -1.546921    -1.540136   -1.556744  -1.546417  1.511255\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "# !--- Modify here if you want ---!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_df)\n",
    "\n",
    "normalized_train_x_df = scaler.transform(train_x_df)\n",
    "normalized_train_x_df = np.transpose(normalized_train_x_df)\n",
    "\n",
    "normalized_train_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_train_x_df[0],\n",
    "    'Close Price': normalized_train_x_df[1],\n",
    "    'High Price': normalized_train_x_df[2],\n",
    "    'Low Price': normalized_train_x_df[3],\n",
    "    'Volume': normalized_train_x_df[4],\n",
    "})\n",
    "\n",
    "normalized_test_x_df = scaler.transform(test_x_df)\n",
    "normalized_test_x_df = np.transpose(normalized_test_x_df)\n",
    "normalized_test_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_test_x_df[0],\n",
    "    'Close Price': normalized_test_x_df[1],\n",
    "    'High Price': normalized_test_x_df[2],\n",
    "    'Low Price': normalized_test_x_df[3],\n",
    "    'Volume': normalized_test_x_df[4],\n",
    "})\n",
    "\n",
    "print(normalized_train_x_df.head())\n",
    "print(train_y_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5475033141847105\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict using Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression(penalty='l1') # !--- Initialize the model here ---!\n",
    "lr_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "lr_training_acc = accuracy_score(train_y_df, lr_model.predict(normalized_train_x_df))\n",
    "print(lr_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "lr_predict_test_result = lr_model.predict(normalized_test_x_df)\n",
    "lr_testing_acc = accuracy_score(test_y_df, lr_predict_test_result)\n",
    "print(lr_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.2765670386184346, 0.5258964143426295, 0.3624977895207681, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(0, 119, 0, 132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, lr_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, lr_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5483870967741935\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict with SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC() # !--- Initialize the model here ---!\n",
    "svc_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "svc_training_acc = accuracy_score(train_y_df, svc_model.predict(normalized_train_x_df))\n",
    "print(svc_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "svc_predict_test_result = svc_model.predict(normalized_test_x_df)\n",
    "svc_testing_acc = accuracy_score(test_y_df, svc_predict_test_result)\n",
    "print(svc_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(svc_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.2765670386184346, 0.5258964143426295, 0.3624977895207681, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(0, 119, 0, 132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, svc_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, svc_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 2)\n",
      "   0  1\n",
      "0  1  0\n",
      "1  0  1\n",
      "2  1  0\n",
      "3  0  1\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "# Define NN output groundtruth\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(train_y_df == 0, 1, 0)[:])\n",
    "train_y_df = pd.DataFrame(data=np.where(train_y_df == 0, 0, 1)[:])\n",
    "train_y_df = pd.concat( [ falling_prob, train_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(test_y_df == 0, 1, 0)[:])\n",
    "test_y_df = pd.DataFrame(data=np.where(test_y_df == 0, 0, 1)[:])\n",
    "test_y_df = pd.concat( [ falling_prob, test_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - loss:447.6631774902\n",
      "epoch:100 - loss:415.8515930176\n",
      "epoch:200 - loss:415.1423645020\n",
      "epoch:300 - loss:414.9292602539\n",
      "epoch:400 - loss:414.8438415527\n",
      "epoch:500 - loss:414.8079528809\n",
      "epoch:600 - loss:414.7925720215\n",
      "epoch:700 - loss:414.7854614258\n",
      "epoch:800 - loss:414.7807922363\n",
      "epoch:900 - loss:414.7761840820\n"
     ]
    }
   ],
   "source": [
    "# Define NN structure\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !--- You can modify the NN structure here ---!\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        acti_out = F.relu(h)\n",
    "        y_pred = self.linear2(h)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N = batch size, D_in = input size, H = hidden size, D_out = output size\n",
    "N, D_in, H, D_out = 300, 5, 100, 2  # !--- You can modify here ---!\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum') # !--- You can modify here ---!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # !--- You can modify here ---!\n",
    "\n",
    "\n",
    "# Train NN\n",
    "# !--- You can modify here ---!\n",
    "\n",
    "for t in range(1000):\n",
    "    for batch_num in range(N, len(normalized_train_x_df), N): \n",
    "        y_pred = model(torch.tensor(normalized_train_x_df[batch_num-N:batch_num].values.astype(np.float32))) # !-- Fill the training batch data here --!\n",
    "        loss = criterion(y_pred,torch.tensor(train_y_df[batch_num-N:batch_num].values.astype(np.float32))) # !-- Fill the prediction & groundtruth here to calculate loss --!\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%100 == 0):\n",
    "        print('epoch:%d - loss:%.10f' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5483870967741935\n",
      "\n",
      "testing accuracy:\n",
      "0.5179282868525896\n",
      "\n",
      "predicted testing prob:\n",
      "tensor([[ 0.0437, -0.0448],\n",
      "        [ 0.0614, -0.0622],\n",
      "        [ 0.0349, -0.0373],\n",
      "        [ 0.0545, -0.0554],\n",
      "        [ 0.0364, -0.0383],\n",
      "        [ 0.0244, -0.0266],\n",
      "        [ 0.0329, -0.0343],\n",
      "        [ 0.0690, -0.0701],\n",
      "        [ 0.0796, -0.0802],\n",
      "        [-0.0254,  0.0263],\n",
      "        [ 0.0918, -0.0907],\n",
      "        [ 0.0274, -0.0296],\n",
      "        [ 0.0684, -0.0704],\n",
      "        [ 0.1102, -0.1094],\n",
      "        [ 0.0590, -0.0612],\n",
      "        [ 0.0279, -0.0280],\n",
      "        [ 0.0301, -0.0317],\n",
      "        [ 0.1246, -0.1236],\n",
      "        [ 0.0089, -0.0105],\n",
      "        [ 0.0177, -0.0193],\n",
      "        [ 0.0293, -0.0298],\n",
      "        [ 0.0632, -0.0639],\n",
      "        [-0.0965,  0.0981],\n",
      "        [-0.2441,  0.2556],\n",
      "        [ 0.2701, -0.2545],\n",
      "        [-0.0053,  0.0071],\n",
      "        [-0.2938,  0.3021],\n",
      "        [ 0.0722, -0.0582],\n",
      "        [ 0.0667, -0.0622],\n",
      "        [ 0.0506, -0.0487],\n",
      "        [ 0.1499, -0.1437],\n",
      "        [ 0.0724, -0.0686],\n",
      "        [ 0.0356, -0.0353],\n",
      "        [-0.0032,  0.0038],\n",
      "        [-0.0430,  0.0450],\n",
      "        [-0.0060,  0.0068],\n",
      "        [ 0.1067, -0.1038],\n",
      "        [ 0.0936, -0.0924],\n",
      "        [-0.0771,  0.0785],\n",
      "        [-0.0901,  0.0918],\n",
      "        [-0.0895,  0.0952],\n",
      "        [ 0.1072, -0.1021],\n",
      "        [ 0.1325, -0.1267],\n",
      "        [ 0.0140, -0.0143],\n",
      "        [ 0.0656, -0.0642],\n",
      "        [ 0.0377, -0.0383],\n",
      "        [ 0.1262, -0.1233],\n",
      "        [ 0.0110, -0.0126],\n",
      "        [-0.0494,  0.0511],\n",
      "        [-0.0464,  0.0468],\n",
      "        [ 0.0014, -0.0022],\n",
      "        [ 0.0598, -0.0629],\n",
      "        [-0.0658,  0.0686],\n",
      "        [ 0.0235, -0.0252],\n",
      "        [ 0.0055, -0.0054],\n",
      "        [-0.1300,  0.1327],\n",
      "        [-0.1743,  0.1792],\n",
      "        [ 0.1179, -0.1106],\n",
      "        [-0.1603,  0.1669],\n",
      "        [-0.0176,  0.0193],\n",
      "        [ 0.0772, -0.0726],\n",
      "        [-0.1586,  0.1667],\n",
      "        [ 0.0568, -0.0526],\n",
      "        [ 0.1682, -0.1574],\n",
      "        [ 0.0186, -0.0187],\n",
      "        [-0.1307,  0.1368],\n",
      "        [-0.0255,  0.0277],\n",
      "        [ 0.0564, -0.0550],\n",
      "        [-0.0113,  0.0108],\n",
      "        [ 0.0312, -0.0316],\n",
      "        [-0.0619,  0.0632],\n",
      "        [ 0.0260, -0.0262],\n",
      "        [ 0.0506, -0.0507],\n",
      "        [ 0.0110, -0.0128],\n",
      "        [-0.0079,  0.0072],\n",
      "        [-0.0525,  0.0531],\n",
      "        [-0.0126,  0.0128],\n",
      "        [-0.1308,  0.1359],\n",
      "        [ 0.0143, -0.0124],\n",
      "        [ 0.0555, -0.0544],\n",
      "        [-0.0081,  0.0071],\n",
      "        [-0.0721,  0.0724],\n",
      "        [ 0.0363, -0.0346],\n",
      "        [-0.0485,  0.0484],\n",
      "        [ 0.0079, -0.0044],\n",
      "        [ 0.1160, -0.1093],\n",
      "        [ 0.0131, -0.0139],\n",
      "        [ 0.0131, -0.0133],\n",
      "        [ 0.0679, -0.0668],\n",
      "        [ 0.0632, -0.0629],\n",
      "        [ 0.0273, -0.0284],\n",
      "        [ 0.0052, -0.0066],\n",
      "        [-0.0063,  0.0051],\n",
      "        [ 0.0408, -0.0419],\n",
      "        [ 0.0157, -0.0163],\n",
      "        [ 0.0038, -0.0062],\n",
      "        [ 0.0364, -0.0380],\n",
      "        [-0.0218,  0.0205],\n",
      "        [ 0.0753, -0.0747],\n",
      "        [ 0.0080, -0.0076],\n",
      "        [ 0.0043, -0.0061],\n",
      "        [-0.0303,  0.0313],\n",
      "        [ 0.0773, -0.0762],\n",
      "        [-0.0162,  0.0148],\n",
      "        [ 0.0634, -0.0638],\n",
      "        [ 0.0365, -0.0388],\n",
      "        [ 0.0234, -0.0251],\n",
      "        [ 0.0828, -0.0822],\n",
      "        [ 0.0157, -0.0166],\n",
      "        [ 0.0614, -0.0622],\n",
      "        [ 0.0317, -0.0341],\n",
      "        [ 0.0337, -0.0357],\n",
      "        [ 0.0015, -0.0036],\n",
      "        [ 0.0319, -0.0340],\n",
      "        [ 0.0665, -0.0677],\n",
      "        [ 0.0499, -0.0505],\n",
      "        [ 0.0576, -0.0576],\n",
      "        [ 0.0236, -0.0261],\n",
      "        [-0.0311,  0.0304],\n",
      "        [ 0.0273, -0.0302],\n",
      "        [-0.0536,  0.0561],\n",
      "        [ 0.0242, -0.0255],\n",
      "        [-0.0687,  0.0706],\n",
      "        [ 0.0654, -0.0635],\n",
      "        [-0.0055,  0.0047],\n",
      "        [ 0.0727, -0.0710],\n",
      "        [-0.0628,  0.0627],\n",
      "        [ 0.0483, -0.0479],\n",
      "        [ 0.0753, -0.0732],\n",
      "        [ 0.0689, -0.0695],\n",
      "        [ 0.0417, -0.0439],\n",
      "        [ 0.0077, -0.0094],\n",
      "        [ 0.0729, -0.0734],\n",
      "        [ 0.0414, -0.0430],\n",
      "        [ 0.0209, -0.0232],\n",
      "        [ 0.0882, -0.0875],\n",
      "        [ 0.0487, -0.0507],\n",
      "        [ 0.0242, -0.0265],\n",
      "        [ 0.0286, -0.0313],\n",
      "        [ 0.0541, -0.0555],\n",
      "        [ 0.0403, -0.0414],\n",
      "        [ 0.1277, -0.1261],\n",
      "        [ 0.0571, -0.0599],\n",
      "        [-0.0269,  0.0276],\n",
      "        [-0.0117,  0.0109],\n",
      "        [ 0.0635, -0.0650],\n",
      "        [ 0.0176, -0.0188],\n",
      "        [ 0.1127, -0.1103],\n",
      "        [ 0.0691, -0.0705],\n",
      "        [ 0.0666, -0.0673],\n",
      "        [ 0.0488, -0.0515],\n",
      "        [ 0.0408, -0.0432],\n",
      "        [ 0.0285, -0.0309],\n",
      "        [ 0.0184, -0.0198],\n",
      "        [-0.0063,  0.0055],\n",
      "        [ 0.0692, -0.0700],\n",
      "        [ 0.0131, -0.0131],\n",
      "        [ 0.0664, -0.0672],\n",
      "        [ 0.0737, -0.0738],\n",
      "        [ 0.0478, -0.0501],\n",
      "        [ 0.0477, -0.0500],\n",
      "        [ 0.0405, -0.0424],\n",
      "        [ 0.0262, -0.0279],\n",
      "        [ 0.0739, -0.0750],\n",
      "        [ 0.0830, -0.0844],\n",
      "        [ 0.0347, -0.0370],\n",
      "        [ 0.0869, -0.0874],\n",
      "        [ 0.0256, -0.0270],\n",
      "        [ 0.0589, -0.0604],\n",
      "        [ 0.0509, -0.0524],\n",
      "        [ 0.0455, -0.0468],\n",
      "        [ 0.0177, -0.0180],\n",
      "        [ 0.0542, -0.0551],\n",
      "        [ 0.0302, -0.0326],\n",
      "        [ 0.0911, -0.0902],\n",
      "        [ 0.0527, -0.0542],\n",
      "        [ 0.0752, -0.0774],\n",
      "        [ 0.0464, -0.0482],\n",
      "        [ 0.0021, -0.0036],\n",
      "        [ 0.0889, -0.0893],\n",
      "        [ 0.0577, -0.0604],\n",
      "        [ 0.0933, -0.0948],\n",
      "        [ 0.0815, -0.0849],\n",
      "        [ 0.0533, -0.0557],\n",
      "        [ 0.0399, -0.0427],\n",
      "        [ 0.0229, -0.0232],\n",
      "        [ 0.0587, -0.0600],\n",
      "        [ 0.0705, -0.0726],\n",
      "        [ 0.0557, -0.0570],\n",
      "        [ 0.0578, -0.0601],\n",
      "        [ 0.0411, -0.0426],\n",
      "        [ 0.0035, -0.0022],\n",
      "        [ 0.0004,  0.0016],\n",
      "        [ 0.0684, -0.0675],\n",
      "        [ 0.0453, -0.0464],\n",
      "        [-0.2139,  0.2203],\n",
      "        [-0.1032,  0.1103],\n",
      "        [ 0.0265, -0.0227],\n",
      "        [-0.0165,  0.0162],\n",
      "        [ 0.1544, -0.1495],\n",
      "        [ 0.0274, -0.0254],\n",
      "        [-0.0661,  0.0691],\n",
      "        [ 0.0083, -0.0071],\n",
      "        [-0.0267,  0.0268],\n",
      "        [ 0.0862, -0.0795],\n",
      "        [-0.2178,  0.2247],\n",
      "        [ 0.1124, -0.1070],\n",
      "        [-0.0039,  0.0094],\n",
      "        [-0.1120,  0.1229],\n",
      "        [ 0.1519, -0.1469],\n",
      "        [ 0.0546, -0.0546],\n",
      "        [ 0.0986, -0.0967],\n",
      "        [-0.0352,  0.0392],\n",
      "        [ 0.0556, -0.0549],\n",
      "        [ 0.0714, -0.0715],\n",
      "        [ 0.1523, -0.1485],\n",
      "        [ 0.0390, -0.0398],\n",
      "        [ 0.0010, -0.0006],\n",
      "        [-0.1157,  0.1184],\n",
      "        [-0.0009,  0.0024],\n",
      "        [-0.0843,  0.0886],\n",
      "        [ 0.1303, -0.1224],\n",
      "        [ 0.0806, -0.0788],\n",
      "        [-0.0988,  0.1016],\n",
      "        [-0.0210,  0.0222],\n",
      "        [-0.0220,  0.0210],\n",
      "        [-0.0284,  0.0275],\n",
      "        [ 0.0757, -0.0749],\n",
      "        [ 0.0617, -0.0605],\n",
      "        [ 0.1721, -0.1645],\n",
      "        [ 0.0208, -0.0199],\n",
      "        [ 0.1077, -0.1068],\n",
      "        [ 0.0438, -0.0438],\n",
      "        [-0.2128,  0.2194],\n",
      "        [-0.2117,  0.2183],\n",
      "        [ 0.1231, -0.1136],\n",
      "        [-0.1665,  0.1737],\n",
      "        [ 0.0236, -0.0162],\n",
      "        [-0.0786,  0.0821],\n",
      "        [-0.0142,  0.0149],\n",
      "        [-0.0173,  0.0183],\n",
      "        [-0.0863,  0.0877],\n",
      "        [-0.1384,  0.1439],\n",
      "        [-0.0484,  0.0510],\n",
      "        [-0.1264,  0.1353],\n",
      "        [-0.0939,  0.0996],\n",
      "        [-0.1394,  0.1469],\n",
      "        [-0.2167,  0.2208],\n",
      "        [ 0.2592, -0.2393],\n",
      "        [ 0.0987, -0.0851],\n",
      "        [-0.0728,  0.0760]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "predicted testing labels:\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "nn_predict_train_y = model(torch.tensor(normalized_train_x_df.values.astype(np.float32))) # !-- Predict training data here --!\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(train_y_df[0], result_train))\n",
    "\n",
    "nn_predict_test_y = model(torch.tensor(normalized_test_x_df.values.astype(np.float32))) # !-- Predict training data here --!\n",
    "result_test = np.where(nn_predict_test_y[:, 0] > nn_predict_test_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(test_y_df[0], result_test))\n",
    "\n",
    "print('\\npredicted testing prob:')\n",
    "print(nn_predict_test_y)\n",
    "print('\\npredicted testing labels:')\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision, recall, fbeta-score:\n",
      "(0.5369588292972485, 0.5179282868525896, 0.4964395354444913, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(42, 90, 31, 88)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('\\nprecision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df[0], result_test, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df[0], result_test).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　三個model做出來的結果都不是很好，且很明顯有很大的bias（顯然是under fitting），有嘗試過調整參數，但並沒有明顯的改善，50%的accuracy也就是說跟亂猜是一樣的（前面兩個model全部都是1還真的是亂猜），可見這些feature並不能決定明天的漲跌，或許可以考慮加入過去幾天的價格資訊來幫助模型預測，或是嘗試使用RNN，利用LSTM讓model能夠得到時間相關的資訊，也許就可以做出比較好的預測。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
